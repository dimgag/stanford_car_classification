{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/Users/dim__gag/Desktop/stanford-cars-dataset/data/car_data/car_data/train\"\n",
    "valid_dir = \"/Users/dim__gag/Desktop/stanford-cars-dataset/data/car_data/car_data/test\"\n",
    "\n",
    "image_size = 224\n",
    "batch_size = 32\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show images from train directory\n",
    "train_images = os.listdir(train_dir)\n",
    "print(\"Number of images in train directory: \", len(train_images))\n",
    "print(\"Sample images from train directory: \", train_images[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show images from valid directory\n",
    "valid_images = os.listdir(valid_dir)\n",
    "print(\"Number of images in valid directory: \", len(valid_images))\n",
    "print(\"Sample images from valid directory: \", valid_images[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    img = plt.imread(train_dir + \"/\" + train_images[i] + \"/\" + os.listdir(train_dir + \"/\" + train_images[i])[0])\n",
    "    plt.imshow(img)\n",
    "    plt.title(train_images[i])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show specific brand images\n",
    "def show_brand_images(brand_name):\n",
    "    \"\"\" Function to find all the models of a \n",
    "    given car brand-name and show their images.\"\"\"\n",
    "    brand_name = str(brand_name)\n",
    "    # Find all the models with a given brand name\n",
    "    car = []\n",
    "    for i in range(len(train_images)):\n",
    "        if brand_name in train_images[i].lower():\n",
    "            # print(train_images[i])\n",
    "            # car = train_images[i]\n",
    "            car.append(train_images[i])\n",
    "    print(car)\n",
    "    # Show one image from every class\n",
    "    plt.figure(figsize=(25, 25))\n",
    "    for i in range(len(car)):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        img = plt.imread(train_dir + \"/\" + car[i] + \"/\" + os.listdir(train_dir + \"/\" + car[i])[0])\n",
    "        plt.imshow(img)\n",
    "        plt.title(car[i])\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "show_brand_images(\"audi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be continued...\n",
    "# https://debuggercafe.com/stanford-cars-classification-using-efficientnet-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "# Required constants.\n",
    "TRAIN_DIR = \"/Users/dim__gag/Desktop/stanford-cars-dataset/data/car_data/car_data/train\"\n",
    "VALID_DIR = \"/Users/dim__gag/Desktop/stanford-cars-dataset/data/car_data/car_data/test\"\n",
    "\n",
    "IMAGE_SIZE = 224 # Image size of resize when applying transforms.\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4 # Number of parallel processes for data preparation.\n",
    "\n",
    "# Training transforms\n",
    "def get_train_transform(IMAGE_SIZE):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(35),\n",
    "        transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.5),\n",
    "        transforms.RandomGrayscale(p=0.5),\n",
    "        transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
    "        transforms.RandomPosterize(bits=2, p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "    ])\n",
    "    return train_transform\n",
    "# Validation transforms\n",
    "def get_valid_transform(IMAGE_SIZE):\n",
    "    valid_transform = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "    ])\n",
    "    return valid_transform\n",
    "\n",
    "def get_datasets():\n",
    "    \"\"\"\n",
    "    Function to prepare the Datasets.\n",
    "    Returns the training and validation datasets along \n",
    "    with the class names.\n",
    "    \"\"\"\n",
    "    dataset_train = datasets.ImageFolder(\n",
    "        TRAIN_DIR, \n",
    "        transform=(get_train_transform(IMAGE_SIZE))\n",
    "    )\n",
    "    dataset_valid = datasets.ImageFolder(\n",
    "        VALID_DIR, \n",
    "        transform=(get_valid_transform(IMAGE_SIZE))\n",
    "    )\n",
    "    return dataset_train, dataset_valid, dataset_train.classes\n",
    "def get_data_loaders(dataset_train, dataset_valid):\n",
    "    \"\"\"\n",
    "    Prepares the training and validation data loaders.\n",
    "    :param dataset_train: The training dataset.\n",
    "    :param dataset_valid: The validation dataset.\n",
    "    Returns the training and validation data loaders.\n",
    "    \"\"\"\n",
    "    train_loader = DataLoader(\n",
    "        dataset_train, batch_size=BATCH_SIZE, \n",
    "        shuffle=True, num_workers=NUM_WORKERS\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        dataset_valid, batch_size=BATCH_SIZE, \n",
    "        shuffle=False, num_workers=NUM_WORKERS\n",
    "    )\n",
    "    return train_loader, valid_loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utlis.py\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "def save_model(epochs, model, optimizer, criterion):\n",
    "    torch.save({\n",
    "        'epoch': epochs,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': criterion,\n",
    "    }, 'model.pth')\n",
    "\n",
    "def save_plots(train_acc, valid_acc, train_loss, valid_loss):\n",
    "    \"\"\"\n",
    "    Function to save the loss and accuracy plots to disk.\n",
    "    \"\"\"\n",
    "    # Accuracy plots.\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(\n",
    "        train_acc, color='green', linestyle='-', \n",
    "        label='train accuracy'\n",
    "    )\n",
    "    plt.plot(\n",
    "        valid_acc, color='blue', linestyle='-', \n",
    "        label='validataion accuracy'\n",
    "    )\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"../outputs/accuracy.png\")\n",
    "    \n",
    "    # Loss plots.\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(\n",
    "        train_loss, color='orange', linestyle='-', \n",
    "        label='train loss'\n",
    "    )\n",
    "    plt.plot(\n",
    "        valid_loss, color='red', linestyle='-', \n",
    "        label='validataion loss'\n",
    "    )\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"../outputs/loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "def build_model(pretrained=True, fine_tune=True, num_classes=10):\n",
    "    if pretrained:\n",
    "        print(\"Loading pre-trained weights\")\n",
    "    else:\n",
    "        print(\"Not loading pre-trained weights\")\n",
    "    model = models.efficientnet_b1(pretrained=pretrained)\n",
    "\n",
    "    if fine_tune:\n",
    "        print(\"Fine-tuning the model\")\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "    elif not fine_tune:\n",
    "        print(\"Not fine-tuning the model\")\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    # Change the Classification Head\n",
    "    model.classifier[1] = nn.Linear(in_features=1280, out_features=num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# from model import build_model\n",
    "# from datasets import get_datasets, get_data_loaders\n",
    "# from utils import save_model, save_plots\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Construct the argument parser and parse the arguments.\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--epochs\", type=int, default=10,\n",
    "    help=\"Number of epochs to train the model\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"-lr\", \"--learning_rate\", type=float, dest=\"learning_rate\", default=0.001,\n",
    "    help=\"Learning rate for the optimizer for training the model\"\n",
    ")\n",
    "args = vars(parser.parse_args())\n",
    "\"\"\"\n",
    "TODO: Remove this block (for now) and add the epoch number and learning rate inside the training funtion.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function - train.py\n",
    "def train(model, trainloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    print('Training')\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    counter = 0\n",
    "    for i, data in tqdm(enumerate(trainloader), total=len(trainloader)):\n",
    "        counter += 1\n",
    "        image, labels = data\n",
    "        image = image.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass.\n",
    "        outputs = model(image)\n",
    "        # Calculate the loss.\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_running_loss += loss.item()\n",
    "        # Calculate the accuracy.\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_running_correct += (preds == labels).sum().item()\n",
    "        # Backpropagation.\n",
    "        loss.backward()\n",
    "        # Update the weights.\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Loss and accuracy for the complete epoch.\n",
    "    epoch_loss = train_running_loss / counter\n",
    "    epoch_acc = 100. * (train_running_correct / len(trainloader.dataset))\n",
    "    return epoch_loss, epoch_acc \n",
    "\n",
    "\n",
    "# Validation function.\n",
    "def validate(model, testloader, criterion, class_names):\n",
    "    model.eval()\n",
    "    print('Validation')\n",
    "    valid_running_loss = 0.0\n",
    "    valid_running_correct = 0\n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(testloader), total=len(testloader)):\n",
    "            counter += 1\n",
    "            \n",
    "            image, labels = data\n",
    "            image = image.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Forward pass.\n",
    "            outputs = model(image)\n",
    "            # Calculate the loss.\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_running_loss += loss.item()\n",
    "            # Calculate the accuracy.\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            valid_running_correct += (preds == labels).sum().item()\n",
    "        \n",
    "    # Loss and accuracy for the complete epoch.\n",
    "    epoch_loss = valid_running_loss / counter\n",
    "    epoch_acc = 100. * (valid_running_correct / len(testloader.dataset))\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Load the training and validation datasets.\n",
    "    dataset_train, dataset_valid, dataset_classes = get_datasets()\n",
    "    print(f\"[INFO]: Number of training images: {len(dataset_train)}\")\n",
    "    print(f\"[INFO]: Number of validation images: {len(dataset_valid)}\")\n",
    "    # Load the training and validation data loaders.\n",
    "    train_loader, valid_loader = get_data_loaders(dataset_train, dataset_valid)\n",
    "    # Learning_parameters. \n",
    "    lr = args['learning_rate']\n",
    "    epochs = args['epochs']\n",
    "    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Computation device: {device}\")\n",
    "    print(f\"Learning rate: {lr}\")\n",
    "    print(f\"Epochs to train for: {epochs}\\n\")\n",
    "    # Load the model.\n",
    "    model = build_model(\n",
    "        pretrained=True,\n",
    "        fine_tune=True, \n",
    "        num_classes=len(dataset_classes)\n",
    "    ).to(device)\n",
    "    \n",
    "    # Total parameters and trainable parameters.\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"{total_params:,} total parameters.\")\n",
    "    total_trainable_params = sum(\n",
    "        p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"{total_trainable_params:,} training parameters.\")\n",
    "    # Optimizer.\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    # Loss function.\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Lists to keep track of losses and accuracies.\n",
    "    train_loss, valid_loss = [], []\n",
    "    train_acc, valid_acc = [], []\n",
    "    # Start the training.\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n",
    "        train_epoch_loss, train_epoch_acc = train(model, train_loader, \n",
    "                                                optimizer, criterion)\n",
    "        valid_epoch_loss, valid_epoch_acc = validate(model, valid_loader,  \n",
    "                                                    criterion, dataset_classes)\n",
    "        train_loss.append(train_epoch_loss)\n",
    "        valid_loss.append(valid_epoch_loss)\n",
    "        train_acc.append(train_epoch_acc)\n",
    "        valid_acc.append(valid_epoch_acc)\n",
    "        print(f\"Training loss: {train_epoch_loss:.3f}, training acc: {train_epoch_acc:.3f}\")\n",
    "        print(f\"Validation loss: {valid_epoch_loss:.3f}, validation acc: {valid_epoch_acc:.3f}\")\n",
    "        print('-'*50)\n",
    "        time.sleep(2)\n",
    "    # Save the trained model weights.\n",
    "    save_model(epochs, model, optimizer, criterion)\n",
    "    # Save the loss and accuracy plots.\n",
    "    save_plots(train_acc, valid_acc, train_loss, valid_loss)\n",
    "    print('TRAINING COMPLETE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45f8683c9252a88b8f420901eacb34fcdb5939f1b6daec3cbc0724dfb08907e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
